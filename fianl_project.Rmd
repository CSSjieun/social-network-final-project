---
title: "Final project"
author: "Jieun Park"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

This is the project to investigate spreading situation by network graph.
Here, we have used the data of social network which indicates the trust in the social relationship. 
We will identify how trust distribution changes as time passes and also will see the vaccination impact.
Here, even though trust is not controlled by the vaccination likewise the pandemic situation, to make the understanding better, we will use the term of vaccination. 

```{r}
library(readr)
library(igraph)
library(dplyr)
library(ggplot2)
library(purrr)
library(tibble)
library(caret)
library(tidyverse)
```

# Function

```{r}
sim_sir <- function(g,beta,mu,seeds){
  state <- rep(0,vcount(g)) #initial state of the simulation
  state[seeds] <- 1 #infect the seeds
  t <- 0
  table <- data.frame(t=0,inf=seeds)
  while(sum(state==1)>0){
    t <- t + 1
    ## I -> R
    infected <- which(state==1) #get them
    # generate a random value for every infected, if it's < mu, let the node recover.
    state[infected] <- ifelse(runif(length(infected)) < mu,2,1)
    
    ## S -> I
    infected <- which(state==1)
    susceptible <- which(state==0) #get them
    contacts <- as.numeric(unlist(adjacent_vertices(g,infected))) #get the contacts of infected
    contacts <- contacts[contacts %in% susceptible] # get those who are susceptible
    new_infected <- contacts[runif(length(contacts)) < beta] #infect contacts
    new_infected <- unique(new_infected) # drop duplicates from the new_infected
    if(length(new_infected)>0){
      state[new_infected] <- 1
      table <- rbind(table,data.frame(t,inf=new_infected))
    }
  }
  table
}
```

# Data collection

```{r}
node <- read.csv("nodes.csv") |> select("X..index", "meta")
edge <- read.csv("edges.csv")

graph <- graph_from_data_frame(edge, vertices = node, directed = FALSE)
graph <- simplify(graph)

cluster <- clusters(graph)
giant_component <- which.max(cluster$csize)
node_giant <- V(graph)[cluster$membership == giant_component]

g <- induced_subgraph(graph, node_giant)
g

```

```{r}
plot(g, vertex.label = NA, vertex.size = 3)
```

# 1. Finding epidemic threshold

```{r}
mu <- 0.1
betac <- mu*mean(degree(g))/(mean(degree(g)^2))
betac
```

# 2. Simulating the SIR model

```{r}
seeds <- sample(1:vcount(g),vcount(g)*0.01)

realization <- sim_sir(g,beta = 0.5,mu=0.1,seeds) %>% 
  group_by(t) %>% summarize(ninf=n()) 
```

```{r}
realization %>% 
  ggplot(aes(x=t, y=ninf)) + 
  geom_line(color = "blue", size = 1) + 
  labs(
    title = "Number of Infections Over Time",
    subtitle = "SIR Model Simulation",
    x = "Time (t)",
    y = "Number of Infections (ninf)"
  ) + 
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

## plot SIR with several beta

```{r}
results <- map_dfr(seq(0,0.2,0.01), # beta range
        \(beta){ seeds <- sample(1:vcount(g),vcount(g)*0.01)
        realization <- sim_sir(g,beta,mu,seeds) # make a realization for each beta
        data.frame(beta,ninf=nrow(realization)) # create dataframe row
        })
```

```{r}
results %>% 
  ggplot(aes(x=beta, y=ninf)) + 
  geom_point(color = "blue", size = 1.5) + 
  geom_vline(xintercept = betac, linetype = "dashed", color = "red", size = 1) + 
  labs(
    title = "Number of Infections with Beta Threshold",
    subtitle = "SIR Model Simulation Results",
    x = "Transmission Rate (beta)",
    y = "Number of Infections (ninf)"
  ) + 
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

# 3. Centrality Proxies

```{r}
realization <- sim_sir(g,beta=0.1,mu=0.1,seeds)
```

### degree

```{r}
set.seed(12345)
table_d <- degree(g) %>% enframe(name = "inf",value="degree") %>%
  merge(realization) 

# Plot
table_d %>% 
  ggplot(aes(x = t, y = degree)) + 
  geom_point(color = "blue", size = 2) + 
  scale_y_log10() + 
  labs(
    title = "Degree Over Time",
    subtitle = "Log-Scaled Degree Distribution",
    x = "Time (t)",
    y = "Degree (log scale)"
  ) + 
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

### closeness

```{r}
set.seed(12345)
table_c <- closeness(g) %>% enframe(name = "inf",value="closeness") %>%
  merge(realization) 

# Plot
table_c %>% 
  ggplot(aes(x = t, y = closeness)) + 
  geom_point(color = "blue", size = 2) + 
  scale_y_log10() + 
  labs(
    title = "Closeness Centrality Over Time",
    subtitle = "Log-Scaled Closeness Centrality Distribution",
    x = "Time (t)",
    y = "Closeness Centrality (log scale)"
  ) + 
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

### betweeness

```{r}
set.seed(12345)
table_b <- betweenness(g) %>% enframe(name = "inf",value="betweenness") %>%
  merge(realization) 

# Plot
table_b %>% 
  ggplot(aes(x = t, y = betweenness)) + 
  geom_point(color = "blue", size = 2) + 
  scale_y_log10() + 
  labs(
    title = "Betweenness Centrality Over Time",
    subtitle = "Log-Scaled Betweenness Centrality Distribution",
    x = "Time (t)",
    y = "Betweenness Centrality (log scale)"
  ) + 
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

### page rank

```{r}
set.seed(12345)
table_pr <- page_rank(g)$vector %>% enframe(name = "inf",value="page_rank") %>%
  merge(realization) 

# Plot
table_pr %>% 
  ggplot(aes(x = t, y = page_rank)) + 
  geom_point(color = "blue", size = 2, alpha = 0.6) + 
  scale_y_log10() + 
  labs(
    title = "PageRank Over Time",
    subtitle = "Log-Scaled PageRank Distribution",
    x = "Time (t)",
    y = "PageRank (log scale)"
  ) + 
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```

```{r}
table <- merge(table_d,table_c)
table <- merge(table,table_pr)
table <- merge(table,table_b)
cor(table$t,table[,-c(1,2)])
```

The highest centrality proxy is 'closeness'. The correlation value between the time and closeness is -0.16. Therefore, as time passes, the closeness of nodes reduces by 0.16.

```{r}
set.seed(12345)
seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization_random <- sim_sir(g,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
seeds <- closeness(g) %>% enframe(name = "inf",value="closeness") %>%
  slice_max(closeness,n=round(vcount(g)*0.01,0))

seeds_inf <- seeds$inf
seeds_inf <- as.integer(seeds_inf)
all(seeds_inf %in% V(g)) 

realization_targeted <- sim_sir(g,beta = 0.5,mu=0.1,seeds_inf) %>%
  group_by(t) %>% summarize(ninf=n())
```

```{r}
ggplot() + geom_line(data=realization_random,aes(x=t,y=ninf,col="Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Targeted")) +
  labs(
    title = "Comparison of Infections Over Time",
    subtitle = "Random vs. Targeted",
    x = "Time (t)",
    y = "Number of Trust Spreading (ninf)",
    color = NULL
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size=14, face="bold"),
    plot.subtitle = element_text(hjust = 0.5, size=12),
    axis.title.x = element_text(size=12),
    axis.title.y = element_text(size=12),
    legend.position = "bottom"
  ) +
  scale_color_manual(values = c("Random" = "blue", "Targeted" = "red"))

```

We have plotted the SIR model distribution with the random and targeted nodes. The parameters are β and µ. β is 0.5 (infection rate is 50%) and µ is 0.1 (recovery rate is 10%). We have chosen the 'closeness' centrality proxy which has the highest correlation with the time.

From the plot, we are able to notice that targeted nodes which has higher closeness centrality value get infected more and bit earlier than the randomly chosen nodes' infection distribution. 
Therefore, we can identify that people who have the highest centrality would get spread the trust from social network faster than randomly selected population from the social network. 

```{r}
total_infected_random <- sum(realization_random$ninf)
total_infected_targeted <- sum(realization_targeted$ninf)
difference_infected <- total_infected_targeted - total_infected_random

print(paste("Total Infected (Random)", total_infected_random))
print(paste("Total Infected (Targeted)", total_infected_targeted))
print(paste("Difference in Infected", difference_infected))
```

Here, we have number of the infected people from random and targeted nodes. Since our data is about the trust, we can interpret that when the nodes are selected randomly, then, the trust spread to 4818 people. If the nodes are selected who have relatively higher centrality than other nodes, then, the trust spread to 4846 people. The difference between two distribution is 28 We can conclude that when nodes have high centrality, trust spreading amount and speed is higher than randomly selected nodes' distribution.

### Vaccinate people not to spread the trust

- Choose those 5% randomly in the network. Simulate the SIR model above using 1% of the remaining nodes as seeds. Choose those seeds randomly.

```{r}
set.seed(12345)

seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta = 0.5,mu=0.1,seeds) |> group_by(t) |> summarize(ninf=n())

vaccinated_random <- sample(1:vcount(g),vcount(g)*0.05)
gp <- delete_vertices(g,vaccinated_random)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_random <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) |> group_by(t) |> summarize(ninf=n())
```

Now, we will do the experiment to investigate the impact of controlled situation (Assuming the situation when 5% of people get vaccinated). We will remove 5% of nodes randomly from the original network assuming those nodes are vaccinated. We hypothesized that the amount of trust spreading would not be large as much as in the normal situation that people are not vaccinated at all. We simulated three situations that people get no vaccinated, randomly selected people are vaccinated, and targeted people who have the highest closeness centrality get vaccinated to see how the trust spreading distribution changes as times goes by.

These are the steps that we have done.
First, we made seeds extracting 1% of the people from the original network graph of g.
Then, we made the SIR model with the seeds. 
The realization is the situation that people do not get vaccinated.

Second, then we sampled 5% of people from the original network graph to simulate the situation the situation when 5% of people get vaccinated randomly then how the trust spreading distribution will be changed. 
The variable named by 'realization_random' is the SIR model that assuming the situation that randomly selected 5% of people get vaccinated. 

### Choose the seeds with largest centrality

- Choose those 5% according to their centrality. Simulate the SIR model above using 1% of the remaining nodes as seeds. Choose those seeds randomly.

```{r}
set.seed(12345)
seeds <- closeness(g) %>% enframe(name = "inf",value="closeness") %>%
  slice_max(closeness,n=round(vcount(g)*0.05,0))
gp <- delete_vertices(g,seeds$inf)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_targeted <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

Third, this is the last scenario which assumes 5% of people who have the highest closeness centrality would be vaccinated. 
'realization_targeted' is the SIR model that assuming the situation that 5% of targeted population would be vaccinated. 

### Measure the difference between both cases

```{r}
ggplot() + geom_line(data=realization,aes(x=t,y=ninf,col="No Vaccination")) +
  geom_line(data=realization_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Vacc. Targeted")) +
  theme_minimal() + labs(
    color = "Vaccination Strategy",  # Set the legend title for the color aesthetic
    title = "Comparison of Trust Spread Over Time",
    subtitle = "No Vaccination vs. Random Vaccination vs. Targeted Vaccination",
    x = "Time (t)",
    y = "Number of trust spread (ninf)"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.position = "bottom"
  ) +
    scale_color_manual(values = c("No Vaccination" = "blue", "Vacc. Random" = "red", "Vacc. Targeted" = "green"))
```

This is the plot to show the impact of the 'vaccination' to control people not to spread the trust as much as in the normal environment. 
As we can expect, when people are not controlled (no vaccination, blue), then the probability of trust spread the most rapidly at the first time period between 0 and 5. 
However, when people get 'vaccinated' then the probability of trust spreading get reduced. 
For example, when randomly selected people are vaccinated (red), then the number of infections get reduced than the not vaccination scenario at the time period between 0 and 5 and the total amount of spread number is also get reduced. 
Moreover, when the population are selected by the closeness centrality, then the impact of the vaccination is even higher. 

Therefore, we can conclude that, when people who have the highest centrality are vaccinated then it is easier to control the infection or spreading speed and amount than vaccinating randomly selected population. 

```{r}
No_Vaccination <- sum(realization$ninf)
Vacc._Random <- sum(realization_random$ninf)
Vacc._Targeted <- sum(realization_targeted$ninf)

print(paste("No Vaccination", No_Vaccination))
print(paste("Vacc. Random", Vacc._Random))
print(paste("Vacc. Targeted", Vacc._Targeted))

partd_w_n_v <- data.frame(partd_label = c("Vacc. Random", "Vacc. Targeted", "Difference in Infected",
                                          "No Vaccination"),
                    pard_value = c(Vacc._Random, Vacc._Targeted, Vacc._Random-Vacc._Targeted,
                                   No_Vaccination))
partd_w_n_v
```

This is the number of infected people (who get the spreading impact of trust). When there is no vaccination control then the infected people are the highest (4818). But once the spreading is controlled, the number get lowered as we explained above with the number of 4506 for random selection and 3982 for targeted selection. Therefore, here we can identify that when there is no vaccination impact then the spreading amount is the highest. Moreover, when it comes to the vaccinated situation of both random nodes or targeted nodes, then the controlling impact is higher for the targeted nodes network than the randomly selected nodes network. The difference of trust spread node number between randomly selected nodes' vaccination and targeted nodes' vaccination is 524.  

### Explanation for part c (1%) and part d (5%)

```{r}
print(paste("Total Infected (Random)", total_infected_random))
print(paste("Total Infected (Targeted)", total_infected_targeted))
print(paste("Difference in Infected", difference_infected))

partc <- data.frame("label" = c("Total Infected (Random)", "Total Infected (Targeted)", 
                                          "Difference in Infected"),
                    "partc_value" = c(total_infected_random, total_infected_targeted, difference_infected))

partd <- partd_w_n_v[-4,]

merged_table <- cbind(partc, partd) |> select(-"partd_label") |> mutate(difference = partc_value - pard_value)

merged_table 
```

At the part c, 1% of population get selected both randomly and targeted. 
When it comes to randomly selected population scenario, 4818 people get spread the trust.
For the targeted population who have the highest closeness centrality scenario, 4846 people get spread the trust.
Difference between two scenarios is 28

At the part d, 5% of population get selected both randomly and targeted.
When it comes to randomly selected population scenario, 4506 people get spread the trust. 
For the targeted population who have the highest closeness centrality scenario, 3982 people get spread the trust
Difference between two scenarios is 524 

From the merged_table, we can identify that when more population is selected, then the impact of control is higher. 
When it comes to randomly selected population scenario, 312 people get more spread trust from the part c than the part d.
For the targeted population who have the highest closeness centrality scenario, 864 people get more spread trust from the part c than the part d.
The total difference between each selection is also higher for the part d than the part c by 496 
Therefore, in any cases, we can say when more people (5%) are selected then the controlling or vaccinating impact is higher than the situation that less people (1%) are selected. 

### Sensor spreading

```{r}
all <- table_d %>% group_by(t) %>% summarize(ninf=n())
sensors <- table_d %>% filter(degree>10) %>% group_by(t) %>% summarize(ninf=n())
```

```{r}
ggplot() + geom_line(data=all,aes(x=t,y=ninf/sum(ninf),col="All")) + geom_line(data=sensors,aes(x=t,y=ninf/sum(ninf),col="Sensors")) +
   labs(
    title = "Sensor Spreading Over Time",
    subtitle = "Comparison Between All and Sensor Data",
    x = "Time (t)",
    y = "Normalized Number of Infections",
    color = "Data Source"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size=14, face="bold"),
    plot.subtitle = element_text(hjust = 0.5, size=12),
    axis.title.x = element_text(size=12),
    axis.title.y = element_text(size=12),
    legend.position = "bottom"
  ) +
  scale_color_manual(values = c("All" = "blue", "Sensors" = "green"))
```

This plot shows how different the normalized number of infection distribution is between all nodes and sensors nodes. 
From the plot we are able to identify that sensor nodes (which have the degree more than 10) would effectively alarm the appearance of the disease or in this case the trust spreading than other all nodes. 

### neighbor

```{r}
control <- sample(1:vcount(g),1000)
get_one_neighbor <- function(id){
  sample(neighbors(g,id),1)
}
sensors <- sapply(control,get_one_neighbor)
```

### cummulative plot

```{r}
control_evo <- table_d %>% filter(inf %in% control) %>% group_by(t) %>% summarize(ninf=n())
sensors_evo <- table_d %>% filter(inf %in% sensors) %>% group_by(t) %>% summarize(ninf=n())
```

```{r}
ggplot() + geom_line(data=control_evo,aes(x=t,y=cumsum(ninf/sum(ninf)),col="All")) +
  geom_line(data=sensors_evo,aes(x=t,y=cumsum(ninf/sum(ninf)),col="Sensors")) +
   labs(
    title = "Cumulative Infections Over Time",
    subtitle = "Comparison Between All and Sensor Data",
    x = "Time (t)",
    y = "Cumulative Proportion of Infections",
    color = "Data Source"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size=14, face="bold"),
    plot.subtitle = element_text(hjust = 0.5, size=12),
    axis.title.x = element_text(size=12),
    axis.title.y = element_text(size=12),
    legend.position = "bottom"
  ) +
  scale_color_manual(values = c("All" = "blue", "Sensors" = "green"))
```

Here, data sources of all and sensors are compared.
All data is randomly selected nodes. 
To get the sensor data, we have used the friendship paradox which means your friends normally have more friends than you. 
When we have used the sensors proxy then there are more people who got infected than the randomly chosen people at the first time period between 0 and 10.
Therefore, we can conclude that we can use the friendship paradox to get to know how the infection or in this case trust spreading distribution changes over time.
People who have more friends would be infected or get spread trust earlier and more at the first time period than randomly selected population.  

# 4. Prediction

### Pre-processing the data

```{r}
# Calculate the quartiles and IQR for each feature
Q1 <- apply(table[, c(-1,-2)], 2, quantile, probs = 0.25)
Q3 <- apply(table[, c(-1,-2)], 2, quantile, probs = 0.75)
IQR <- Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR

# Identify outliers for each feature
outliers <- apply(table[, c(-1,-2)], 2, function(x) x < lower_bound | x > upper_bound)

# Combine the outlier flags across features
outliers_combined <- apply(outliers, 1, any)

# Remove outliers from the dataset
data_no_outliers <- table[!outliers_combined, ]

# Check the dimensions of the dataset before and after removing outliers
dim(table)  # Original dimensions
dim(data_no_outliers)    # Dimensions after removing outliers
```


### 1. Linear Regression

```{r}
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(data_no_outliers$t, p = 0.8, list = FALSE)
test_data <- data_no_outliers[-train_index, ] |> select(-inf)
train_data <- data_no_outliers[train_index, ] |> select(-inf)
```

```{r}
set.seed(123)
control <- trainControl(method = "cv",  # Use k-fold cross-validation
                        number = 100)

# Train a regression model
model <- train(t ~ degree + closeness + page_rank + betweenness,
               data = train_data, method = "lm", trControl = control)
summary(model)
```

```{r}
ggplot(train_data, aes(x = seq(1:50), y = t)) +
  geom_point(aes(x = degree), color = "blue") +
  geom_smooth(aes(x = degree), method = "lm", se = FALSE, color = "blue", formula = y ~ x) +
  geom_point(aes(x = closeness), color = "red") +
  geom_smooth(aes(x = closeness), method = "lm", se = FALSE, color = "red", formula = y ~ x) +
  geom_point(aes(x = page_rank), color = "yellow") +
  geom_smooth(aes(x = page_rank), method = "lm", se = FALSE, color = "yellow", formula = y ~ x) +
  geom_point(aes(x = betweenness), color = "pink") +
  geom_smooth(aes(x = betweenness), method = "lm", se = FALSE, color = "pink", formula = y ~ x) +
  labs(title = "Regression Lines for Different Features",
       x = "Sequence (1 to 50)",
       y = "t") +
  theme_minimal()
  
```

```{r}
cv_results <- model$results
cv_results
```

```{r}
set.seed(123)
x <- as.matrix(train_data[,-1])
y <- train_data$t

control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

ridge_model <- train(
  x, y,
  method = "glmnet",
  trControl = control,
  tuneGrid = expand.grid(alpha = 0, lambda = 10^seq(-3, 0, length = 100))
)

best_tune <- ridge_model$bestTune
best_tune
```

Since the RMSE is too high, we have used the ridge regularization (L2 regularization).

```{r}
prediciton <- predict(ridge_model, newdata = x)
sqrt(mean((prediciton - y)^2))
```

```{r}
# RMSE Calculation for Ridge Regression
predictions_train <- predict(ridge_model, newdata = x)
rmse_train <- sqrt(mean((predictions_train - y)^2))
print(paste("RMSE on train data (Ridge):", rmse_train))

# RMSE Calculation for Test Data
predictions_test <- predict(ridge_model, newdata = test_data)
rmse_test <- sqrt(mean((predictions_test - test_data$t)^2))
print(paste("RMSE on test data (Ridge):", rmse_test))

# Data Frame with RMSE Values
RMSE_ridge <- data.frame(data = c("train", "test"), 
                         RMSE = c(rmse_train, rmse_test))
RMSE_ridge
```

Even though, we have used the 5-fold cross validation and ridge regularization (L2), the RMSE is still high as 3.63 for the test data set. We consider this happens because the scale of the input data are different. 


### 2. Random Forest

```{r}
### 2. Random Forest
# install.packages("randomForest")
library(randomForest)
test_data <- table[-train_index, ] 
train_control <- trainControl(
  method = "cv", 
  number = 5,
  savePredictions = TRUE
)

# Train the random forest model
set.seed(123)
rf_model <- train(
  t ~ ., 
  data = train_data, 
  method = "ranger",
  trControl = train_control,
  tuneLength = 5,
  metric = "RMSE"
)

test_predictions <- predict(rf_model, newdata = test_data)

test_results <- test_data %>%
  mutate(predictions = test_predictions)


rmse_value <- RMSE(test_results$predictions, test_results$t)
rsq_value <- R2(test_results$predictions, test_results$t)

cat("Test RMSE:", rmse_value, "\n")
cat("Test R-squared:", rsq_value, "\n")
```

As shown in the results above, employing the random forest method has led to a significant improvement in the RMSE, bringing it down to 0.4517. This indicates a better fit for our predictions, with the deviations from the actual values averaging 0.4517 units. Additionally, we achieved an R-squared value of 0.6934, meaning that 69.34% of the variability in the time to infection is explained by the model's predictors.

# Using RF model to repeat d)
Selecting the nodes based on the RF predicted time of infection 

### 5%
### Random-realization

```{r}
set.seed(12345)

# Select nodes with the smallest predicted time to infection (top 5% of nodes)
num_seeds <- sample(1:vcount(g),vcount(g)*0.01)
seed_nodes <- test_results %>%
  arrange(predictions) %>%
  slice_head(n = num_seeds) %>%
  pull(inf) # Assuming 'name' column has node IDs

gp <- delete_vertices(g,seed_nodes)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_random <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) |> group_by(t) |> summarize(ninf=n())
```

### Targeted-realization

```{r}
set.seed(12345)

closeness_centrality <- closeness(g)

# Convert closeness centrality to a tibble
closeness_df <- enframe(closeness_centrality, name = "inf", value = "closeness")

# Select the top nodes based on closeness centrality
num_seeds <- round(vcount(g) * 0.05)
seed_nodes <- closeness_df %>%
  slice_max(closeness, n = num_seeds) %>%
  pull(inf)

gp <- delete_vertices(g,seed_nodes)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_targeted <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

```{r}
ggplot() + 
  geom_line(data=realization_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Vacc. Targeted")) +
  theme_minimal() + labs(
    color = "Vaccination Strategy",  # Set the legend title for the color aesthetic
    title = "Comparison of Trust Spread Over Time",
    subtitle = "Random Vaccination vs. Targeted Vaccination",
    x = "Time (t)",
    y = "Number of trust spread (ninf)"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.position = "bottom"
  ) +
    scale_color_manual(values = c("Vacc. Random" = "red", "Vacc. Targeted" = "green"))
```

```{r}
Vacc._Random <- sum(realization_random$ninf)
Vacc._Targeted <- sum(realization_targeted$ninf)

print(paste("Vacc. Random", Vacc._Random))
print(paste("Vacc. Targeted", Vacc._Targeted))

partd_w_n_v <- data.frame(partd_label = c("Vacc. Random", "Vacc. Targeted", "Difference in Infected"),
                    pard_value = c(Vacc._Random, Vacc._Targeted, Vacc._Random-Vacc._Targeted))
partd_w_n_v
```


### Explanation for part c (1%) and part d (5%) 

```{r}
print(paste("Total Infected (Random)", total_infected_random))
print(paste("Total Infected (Targeted)", total_infected_targeted))
print(paste("Difference in Infected", difference_infected))

partc <- data.frame("label" = c("Total Infected (Random)", "Total Infected (Targeted)", 
                                          "Difference in Infected"),
                    "partc_value" = c(total_infected_random, total_infected_targeted, difference_infected))

partd <- partd_w_n_v[-4,]

merged_table <- cbind(partc, partd) |> select(-"partd_label") |> mutate(difference = partc_value - pard_value)

merged_table 
```
